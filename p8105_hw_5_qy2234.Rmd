---
title: "p8105_hw5_qy2234"
author: "Michael Yan"
date: "11/5/2019"
output: github_document
---
```{r setup, include=FALSE}
## general setup
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(viridis)
library(readxl)
library(patchwork)
devtools::install_github("benmarwick/wordcountaddin", type = "source", dependencies = TRUE)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1
```{r}
## load in the given dataset and clean the names
set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()
```

```{r}
## create a funciton that fill in the missing values 
fill_missing = function(x) {
  if (is.numeric(x)) {
     x = replace_na(x, round(mean(x, na.rm = TRUE),1))
  }
  else if (is.character(x)) {
     x = replace_na(x, "virginica")
  }
  x
}
map(iris_with_missing, fill_missing) %>% 
  bind_cols()
```

# Problem 2
```{r}
## import data, create a read file function, combine files
file_names = list.files("./data")

read_file = function(x) {
  path = str_c("./data/",x)
  read_csv(path)
}

combined_df = 
  purrr::map(file_names,read_file) %>%
  bind_rows() %>% 
  janitor::clean_names() %>%
  mutate(file_names = file_names) %>% 
  separate(file_names, into = c("arm", "id"), sep = "_") %>% 
  mutate(arm = recode(arm, 
                            "con" = "control", 
                            "exp" = "experimental")) %>%
  mutate(id = str_remove(id,".csv")) %>% 
  select(id, arm, everything())

combined_df %>%
  knitr::kable()
```

```{r}
# make a spaghetti plot showing observations on each subject over time
combined_df %>% 
  pivot_longer(week_1:week_8,
               names_to = "week",
               values_to = "readings") %>% 
  ggplot(aes(x = week, y = readings, color = id, group = id)) +
  geom_line() +
  geom_point(aes(shape = arm), alpha = .5) +
  facet_grid(.~arm) +
  labs(title = "Spaghetti plots based on arm",
       x = "Week",
       y = "Readings")
```

* Based on the spaghetti plots made, we can see that there is not really an increase or a decrease for the control group. The observations for individuals fluctuate a lot but basiclly stay the same across the period of the experiment. There is not a significant enough trend. On the other hand, for the experimental group, although individual data still fluatuates a lot, there is a obvious increasing trend as the experiment proceed. In general, we see a higher average reading for the individuals in the experimental group compared to the ones from the control group.

# Problem 3
```{r}
## create a function that does simple linear regression(get the estimate and p-value)
set.seed(10)
sim_line_regression = function(n = 30, beta0 = 2, beta1 = 0) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, sqrt(50))
  )
  
  ls_fit = lm(y ~ x, data = sim_data) %>% 
    broom::tidy()
  tibble(
    beta1_hat = ls_fit[[2,2]],
    p_value = ls_fit[[2,5]]
  )
}
```

```{r}
## generate 10000 datasets from the model created
set.seed(10)

generate_10000_list =
  rerun(10000, sim_line_regression(beta1 = 0)) %>%
  bind_rows()

generate_10000_list
```

```{r}
## try using beta1 = {1,2,3,4,5,6}
set.seed(10)

different_beta1_lists = 
  tibble(beta1 = c(1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(beta1, ~rerun(10000, sim_line_regression(beta1 = .x)))) %>%
  unnest(output_lists) %>% 
  unnest()
```


